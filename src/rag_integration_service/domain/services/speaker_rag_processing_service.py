"""
Speaker RAG Processing Service

Domain service for speaker-specific RAG processing operations.
Implements business logic for error-correction pair generation and speaker-specific vectorization.
"""

import re
from decimal import Decimal
from typing import Any, Dict, List, Optional, Tuple
from uuid import UUID

from ..entities.speaker_error_correction_pair import SpeakerErrorCorrectionPair
from ..entities.speaker_rag_processing_job import JobType, SpeakerRAGProcessingJob


class SpeakerRAGProcessingService:
    """
    Domain service for speaker-specific RAG processing operations.

    This service implements the core business logic for processing speaker historical data,
    extracting error-correction pairs, and preparing data for speaker-specific RAG training.
    """

    def __init__(self):
        """Initialize the speaker RAG processing service."""
        pass

    def extract_error_correction_pairs(
        self,
        asr_text: str,
        final_text: str,
        speaker_id: UUID,
        historical_data_id: UUID,
        context_window: int = 50,
    ) -> List[SpeakerErrorCorrectionPair]:
        """
        Extract error-correction pairs from ASR and final text.

        Args:
            asr_text: Original ASR text
            final_text: Final corrected text
            speaker_id: Speaker identifier
            historical_data_id: Historical data identifier
            context_window: Context window size in characters

        Returns:
            List of error-correction pairs
        """
        # Normalize texts for processing
        asr_normalized = self._normalize_text(asr_text)
        final_normalized = self._normalize_text(final_text)

        # Tokenize texts into sentences
        asr_sentences = self._tokenize_sentences(asr_normalized)
        final_sentences = self._tokenize_sentences(final_normalized)

        # Align sentences and extract differences
        pairs = []
        aligned_sentences = self._align_sentences(asr_sentences, final_sentences)

        for asr_sent, final_sent, alignment_score in aligned_sentences:
            if (
                asr_sent != final_sent and alignment_score > 0.3
            ):  # Threshold for meaningful alignment
                # Extract word-level differences
                word_pairs = self._extract_word_level_differences(asr_sent, final_sent)

                for error_phrase, correction_phrase, confidence in word_pairs:
                    # Get context around the error
                    context_before, context_after = self._extract_context(
                        asr_text, error_phrase, context_window
                    )

                    # Create error-correction pair
                    pair = SpeakerErrorCorrectionPair(
                        id=UUID(),  # Will be generated by repository
                        speaker_id=speaker_id,
                        historical_data_id=historical_data_id,
                        error_text=error_phrase,
                        correction_text=correction_phrase,
                        context_before=context_before,
                        context_after=context_after,
                        confidence_score=Decimal(str(confidence)),
                    )

                    # Only include if suitable for training
                    if pair.is_suitable_for_training():
                        pairs.append(pair)

        return pairs

    def categorize_error_patterns(
        self, error_correction_pairs: List[SpeakerErrorCorrectionPair]
    ) -> Dict[str, List[SpeakerErrorCorrectionPair]]:
        """
        Categorize error-correction pairs by error patterns.

        Args:
            error_correction_pairs: List of error-correction pairs

        Returns:
            Dictionary mapping error types to pairs
        """
        categorized = {}

        for pair in error_correction_pairs:
            error_type = self._classify_error_type(
                pair.error_text, pair.correction_text
            )
            pair.error_type = error_type

            if error_type not in categorized:
                categorized[error_type] = []

            categorized[error_type].append(pair)

        return categorized

    def generate_speaker_specific_prompts(
        self, error_correction_pairs: List[SpeakerErrorCorrectionPair], speaker_id: UUID
    ) -> List[Dict[str, str]]:
        """
        Generate speaker-specific prompts for RAG training.

        Args:
            error_correction_pairs: List of error-correction pairs
            speaker_id: Speaker identifier

        Returns:
            List of training prompts
        """
        prompts = []

        # Group pairs by error type for better training
        categorized_pairs = self.categorize_error_patterns(error_correction_pairs)

        for error_type, pairs in categorized_pairs.items():
            # Create type-specific prompts
            for pair in pairs:
                prompt = self._create_training_prompt(pair, error_type)
                prompts.append(prompt)

        return prompts

    def calculate_speaker_error_frequency(
        self, error_correction_pairs: List[SpeakerErrorCorrectionPair]
    ) -> Dict[str, Dict[str, Any]]:
        """
        Calculate error frequency statistics for a speaker.

        Args:
            error_correction_pairs: List of error-correction pairs

        Returns:
            Dictionary with error frequency statistics
        """
        if not error_correction_pairs:
            return {}

        # Count errors by type
        error_counts = {}
        total_pairs = len(error_correction_pairs)

        for pair in error_correction_pairs:
            error_type = pair.categorize_error_type()
            if error_type not in error_counts:
                error_counts[error_type] = {
                    "count": 0,
                    "examples": [],
                    "avg_confidence": 0.0,
                }

            error_counts[error_type]["count"] += 1
            error_counts[error_type]["examples"].append(
                {
                    "error": pair.error_text,
                    "correction": pair.correction_text,
                    "confidence": (
                        float(pair.confidence_score) if pair.confidence_score else 0.0
                    ),
                }
            )

        # Calculate statistics
        for error_type, data in error_counts.items():
            data["frequency"] = data["count"] / total_pairs
            data["percentage"] = (data["count"] / total_pairs) * 100

            # Calculate average confidence
            confidences = [
                ex["confidence"] for ex in data["examples"] if ex["confidence"] > 0
            ]
            data["avg_confidence"] = (
                sum(confidences) / len(confidences) if confidences else 0.0
            )

            # Keep only top examples
            data["examples"] = sorted(
                data["examples"], key=lambda x: x["confidence"], reverse=True
            )[:5]

        return error_counts

    def _normalize_text(self, text: str) -> str:
        """
        Normalize text for processing.

        Args:
            text: Input text

        Returns:
            Normalized text
        """
        if not text:
            return ""

        # Remove extra whitespace
        text = re.sub(r"\s+", " ", text)

        # Normalize punctuation spacing
        text = re.sub(r"\s*([.!?])\s*", r"\1 ", text)

        return text.strip()

    def _tokenize_sentences(self, text: str) -> List[str]:
        """
        Tokenize text into sentences.

        Args:
            text: Input text

        Returns:
            List of sentences
        """
        # Simple sentence tokenization
        sentences = re.split(r"[.!?]+", text)
        return [s.strip() for s in sentences if s.strip()]

    def _align_sentences(
        self, asr_sentences: List[str], final_sentences: List[str]
    ) -> List[Tuple[str, str, float]]:
        """
        Align sentences between ASR and final text.

        Args:
            asr_sentences: ASR sentences
            final_sentences: Final sentences

        Returns:
            List of (asr_sentence, final_sentence, alignment_score) tuples
        """
        aligned = []

        # Simple alignment based on sentence position and similarity
        max_len = max(len(asr_sentences), len(final_sentences))

        for i in range(max_len):
            asr_sent = asr_sentences[i] if i < len(asr_sentences) else ""
            final_sent = final_sentences[i] if i < len(final_sentences) else ""

            # Calculate simple similarity score
            similarity = self._calculate_sentence_similarity(asr_sent, final_sent)
            aligned.append((asr_sent, final_sent, similarity))

        return aligned

    def _calculate_sentence_similarity(self, sent1: str, sent2: str) -> float:
        """
        Calculate similarity between two sentences.

        Args:
            sent1: First sentence
            sent2: Second sentence

        Returns:
            Similarity score (0.0 to 1.0)
        """
        if not sent1 and not sent2:
            return 1.0

        if not sent1 or not sent2:
            return 0.0

        words1 = set(sent1.lower().split())
        words2 = set(sent2.lower().split())

        if not words1 and not words2:
            return 1.0

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        return len(intersection) / len(union) if union else 0.0

    def _extract_word_level_differences(
        self, asr_sentence: str, final_sentence: str
    ) -> List[Tuple[str, str, float]]:
        """
        Extract word-level differences between sentences.

        Args:
            asr_sentence: ASR sentence
            final_sentence: Final sentence

        Returns:
            List of (error_phrase, correction_phrase, confidence) tuples
        """
        differences = []

        asr_words = asr_sentence.split()
        final_words = final_sentence.split()

        # Simple word-by-word comparison
        max_len = max(len(asr_words), len(final_words))

        i = 0
        while i < max_len:
            if i >= len(asr_words):
                # Insertion in final text
                differences.append(("", final_words[i], 0.8))
            elif i >= len(final_words):
                # Deletion from ASR text
                differences.append((asr_words[i], "", 0.8))
            elif asr_words[i] != final_words[i]:
                # Substitution
                differences.append((asr_words[i], final_words[i], 0.9))

            i += 1

        return differences

    def _extract_context(
        self, full_text: str, error_phrase: str, context_window: int
    ) -> Tuple[Optional[str], Optional[str]]:
        """
        Extract context around an error phrase.

        Args:
            full_text: Full text containing the error
            error_phrase: Error phrase to find context for
            context_window: Context window size in characters

        Returns:
            Tuple of (context_before, context_after)
        """
        if not error_phrase or error_phrase not in full_text:
            return None, None

        error_pos = full_text.find(error_phrase)

        # Extract context before
        start_pos = max(0, error_pos - context_window)
        context_before = full_text[start_pos:error_pos].strip()

        # Extract context after
        end_pos = min(len(full_text), error_pos + len(error_phrase) + context_window)
        context_after = full_text[error_pos + len(error_phrase) : end_pos].strip()

        return context_before if context_before else None, (
            context_after if context_after else None
        )

    def _classify_error_type(self, error_text: str, correction_text: str) -> str:
        """
        Classify the type of error based on error and correction text.

        Args:
            error_text: Error text
            correction_text: Correction text

        Returns:
            Error type classification
        """
        if not error_text and correction_text:
            return "insertion"
        elif error_text and not correction_text:
            return "deletion"
        elif error_text and correction_text:
            # Check for common medical transcription error patterns
            if self._is_medical_terminology_error(error_text, correction_text):
                return "medical_terminology"
            elif self._is_number_error(error_text, correction_text):
                return "numeric"
            elif self._is_punctuation_error(error_text, correction_text):
                return "punctuation"
            else:
                return "substitution"
        else:
            return "unknown"

    def _is_medical_terminology_error(
        self, error_text: str, correction_text: str
    ) -> bool:
        """Check if error involves medical terminology."""
        medical_indicators = [
            "mg",
            "ml",
            "cc",
            "dr",
            "patient",
            "diagnosis",
            "treatment",
        ]
        error_lower = error_text.lower()
        correction_lower = correction_text.lower()

        return any(
            term in error_lower or term in correction_lower
            for term in medical_indicators
        )

    def _is_number_error(self, error_text: str, correction_text: str) -> bool:
        """Check if error involves numbers."""
        return bool(re.search(r"\d", error_text) or re.search(r"\d", correction_text))

    def _is_punctuation_error(self, error_text: str, correction_text: str) -> bool:
        """Check if error involves punctuation."""
        return bool(
            re.search(r"[.!?,:;]", error_text)
            or re.search(r"[.!?,:;]", correction_text)
        )

    def _create_training_prompt(
        self, pair: SpeakerErrorCorrectionPair, error_type: str
    ) -> Dict[str, str]:
        """
        Create a training prompt from an error-correction pair.

        Args:
            pair: Error-correction pair
            error_type: Type of error

        Returns:
            Training prompt dictionary
        """
        return {
            "instruction": f"Correct the following {error_type} error in medical transcription:",
            "input": pair.get_full_context(),
            "output": pair.get_correction_context(),
            "error_type": error_type,
            "speaker_id": str(pair.speaker_id),
            "confidence": (
                str(pair.confidence_score) if pair.confidence_score else "0.0"
            ),
        }
